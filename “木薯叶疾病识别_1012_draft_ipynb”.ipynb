{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“木薯叶疾病识别-1012-draft.ipynb”",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://gist.github.com/yefang008514/597a7d4347c7e564737735cc2e187627#file--1012-draft-ipynb-ipynb",
      "authorship_tag": "ABX9TyO5/mrSyRTWnmRIUxWl+D2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yefang008514/machinelearning/blob/master/%E2%80%9C%E6%9C%A8%E8%96%AF%E5%8F%B6%E7%96%BE%E7%97%85%E8%AF%86%E5%88%AB_1012_draft_ipynb%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PqCMSljz5OS"
      },
      "source": [
        "import os #连接到我的云盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgHiX-9oCDsN"
      },
      "source": [
        "import os, sys, glob, argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time, datetime\n",
        "import pdb, traceback\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn          #\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzbXauyKcxEO"
      },
      "source": [
        "# import shutil\n",
        "# # os.mkdir('/content/sample_data/mushuye')\n",
        "# # os.mkdir('/content/sample_data/mushuye/train')\n",
        "# shutil.copytree('/content/drive/MyDrive/mushuye/train','/content/sample_data/mushuye/train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS8Pco72dolr",
        "outputId": "62afe28b-15ed-4b1e-b385-6ae0ee0ca26a"
      },
      "source": [
        "# os.listdir('/content/sample_data/mushuye/train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgfRbcCqMJgL"
      },
      "source": [
        "# import shutil\n",
        "# os.mkdir('/content/mushuye/data/train/')\n",
        "# os.mkdir('/content/mushuye/data/train/CBB')\n",
        "# os.mkdir('/content/mushuye/data/train/CBSD')\n",
        "# os.mkdir('/content/mushuye/data/train/CGM')\n",
        "# os.mkdir('/content/mushuye/data/train/CMD')\n",
        "# os.mkdir('/content/mushuye/data/train/H')\n",
        "# os.mkdir('/content/mushuye/data/train/AL')\n",
        "# img_name=[]\n",
        "# for i in range(0,6):\n",
        "#   img_name.append(train_table[train_table['label']==i]['image_id'])\n",
        "\n",
        "# for j in range(0,6):#读取图片路径并保存\n",
        "#   for k in img_name[j]:\n",
        "#     path = '/content/mushuye/data/train_img/'+k\n",
        "#     if j==0: \n",
        "#       path_to = '/content/mushuye/data/train/CBB/'+k\n",
        "#     elif j==1:\n",
        "#       path_to = '/content/mushuye/data/train/CBSD/'+k\n",
        "#     elif j==2:\n",
        "#       path_to = '/content/mushuye/data/train/CGM/'+k\n",
        "#     elif j==3:\n",
        "#       path_to = '/content/mushuye/data/train/CMD/'+k\n",
        "#     elif j==4:\n",
        "#       path_to = '/content/mushuye/data/train/H/'+k\n",
        "#     elif j==5:\n",
        "#       path_to = '/content/mushuye/data/train/AL/'+k\n",
        "#     # print(path,j,path_to) \n",
        "#     shutil.copy(path,path_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiun62fl2jPd"
      },
      "source": [
        "train_jpg = glob.glob(r'/content/drive/MyDrive/mushuye/train/*/*')\n",
        "np.random.shuffle(train_jpg)\n",
        "train_jpg = np.array(train_jpg)\n",
        "    \n",
        "class QRDataset(Dataset):\n",
        "    def __init__(self, img_path, transform=None):\n",
        "        self.img_path = img_path\n",
        "        if transform is not None:\n",
        "            self.transform = transform\n",
        "        else:\n",
        "            self.transform = None\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        start_time = time.time()\n",
        "        img = Image.open(self.img_path[index]).convert('RGB')\n",
        "        #图片给标签\n",
        "        lbl_dict = {\n",
        "             'CBB': 0,\n",
        "             'CBSD': 1,\n",
        "             'CGM': 2,\n",
        "             'CMD': 3,\n",
        "             'H': 4,\n",
        "             'AL': 5,\n",
        "             }\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        if 'test' in self.img_path[index]:\n",
        "            return img, torch.from_numpy(np.array(0))\n",
        "        else:\n",
        "            lbl_int = lbl_dict[self.img_path[index].split('/')[-2]]\n",
        "            return img, torch.from_numpy(np.array(lbl_int))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOd-r0hhOeM0",
        "outputId": "45fa3303-b850-4f16-cc39-00cff81c695e"
      },
      "source": [
        "train_jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/drive/MyDrive/mushuye/train/CBB/1546870332.jpg',\n",
              "       '/content/drive/MyDrive/mushuye/train/AL/Train_1437.jpg',\n",
              "       '/content/drive/MyDrive/mushuye/train/H/2416129952.jpg', ...,\n",
              "       '/content/drive/MyDrive/mushuye/train/CBB/3142477676.jpg',\n",
              "       '/content/drive/MyDrive/mushuye/train/AL/Train_121.jpg',\n",
              "       '/content/drive/MyDrive/mushuye/train/H/2224228735.jpg'],\n",
              "      dtype='<U56')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCYQ_7RiHOUM"
      },
      "source": [
        "class XunFeiNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XunFeiNet, self).__init__()\n",
        "                \n",
        "        model = models.resnet18(True)        #https://pytorch.org/vision/stable/models.html RESNET\n",
        "        model.avgpool = nn.AdaptiveAvgPool2d(1)   #POOLING\n",
        "        model.fc = nn.Linear(512, 6)        #FULLY CONNETCTED NETWORK https://pytorch.org/docs/stable/nn.html#linear-layers\n",
        "        self.resnet = model\n",
        "         \n",
        "    def forward(self, img):        \n",
        "        out = self.resnet(img)\n",
        "        return out\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    model.eval()\n",
        "    acc1 = []\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "            \n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            acc1.append((output.argmax(1) == target).float().mean().item())\n",
        "\n",
        "        print(' * Val Acc@1 {0}'.format(np.mean(acc1)))\n",
        "        return np.mean(acc1)\n",
        "\n",
        "def predict(test_loader, model, tta=10):\n",
        "    model.eval()\n",
        "    \n",
        "    test_pred_tta = None\n",
        "    for _ in range(tta):\n",
        "        test_pred = []\n",
        "        with torch.no_grad():\n",
        "            end = time.time()\n",
        "            for i, (input, target) in enumerate(test_loader):\n",
        "                input = input.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "                output = model(input)\n",
        "                output = output.data.cpu().numpy()\n",
        "\n",
        "                test_pred.append(output)\n",
        "        test_pred = np.vstack(test_pred)\n",
        "    \n",
        "        if test_pred_tta is None:\n",
        "            test_pred_tta = test_pred\n",
        "        else:\n",
        "            test_pred_tta += test_pred\n",
        "    \n",
        "    return test_pred_tta\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    acc1 = []\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        input = input.cuda(non_blocking=True)\n",
        "        target = target.cuda(non_blocking=True)\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        acc1.append((output.argmax(1) == target).float().mean().item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('Train: {0}'.format(np.mean(acc1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561,
          "referenced_widgets": [
            "5eb68ea193544294ab5a0544f15da347"
          ]
        },
        "id": "XRCmrEgVHYTc",
        "outputId": "d2c7cdd3-fec2-4b7f-e64f-2d01238ebcf3"
      },
      "source": [
        "skf = KFold(n_splits=5, random_state=2334, shuffle=True)\n",
        "for flod_idx, (train_idx, val_idx) in enumerate(skf.split(train_jpg, train_jpg)):\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        QRDataset(train_jpg[train_idx][:],\n",
        "                transforms.Compose([\n",
        "                            transforms.Resize((124, 124)),        \n",
        "                            transforms.RandomAffine(10),\n",
        "                            transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "                            transforms.RandomHorizontalFlip(),\n",
        "                            transforms.RandomVerticalFlip(),\n",
        "                            # transforms.Resize((124, 124)),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                            # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "            ])\n",
        "        ), batch_size=50, shuffle=True, num_workers=5, pin_memory=True\n",
        "    )\n",
        "    \n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        QRDataset(train_jpg[val_idx][:1000],\n",
        "                transforms.Compose([\n",
        "                            # transforms.Resize((300, 400)),\n",
        "                            transforms.Resize((124, 124)),\n",
        "                            # transforms.RandomCrop((88, 88)),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                            # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "            ])\n",
        "        ), batch_size=10, shuffle=False, num_workers=5, pin_memory=True\n",
        "    )\n",
        "        \n",
        "    model = XunFeiNet().cuda()\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), 0.003)\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(10):\n",
        "        print('\\nEpoch: ', epoch)\n",
        "\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "        val_acc = validate(val_loader, model, criterion)\n",
        "        \n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), './resnet18_fold{0}.pt'.format(flod_idx))\n",
        "            \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eb68ea193544294ab5a0544f15da347",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.03999999910593033\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1c053a9f5270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-515eeaff0f80>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0macc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stv5CDjR7iGU"
      },
      "source": [
        "#保存模型\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/resnet18_fold{0}.pt'.format(flod_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_u8fcR5Bijo"
      },
      "source": [
        "# 下面没有用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMNHVmo2ObjK"
      },
      "source": [
        "test_jpg = glob.glob('./Datawhale_人脸情绪识别_数据集/test/*')\n",
        "test_jpg = np.array(test_jpg)\n",
        "test_jpg.sort()\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        QRDataset(test_jpg,\n",
        "                transforms.Compose([\n",
        "                            transforms.RandomHorizontalFlip(),\n",
        "                            transforms.RandomVerticalFlip(),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        ), batch_size=50, shuffle=False, num_workers=5, pin_memory=True\n",
        ")\n",
        "        \n",
        "model = XunFeiNet().cuda()\n",
        "model.load_state_dict(torch.load('resnet18_fold0.pt'))\n",
        "test_pred = predict(test_loader, model, 5)\n",
        "\n",
        "\n",
        "# test_csv = pd.DataFrame()\n",
        "# test_csv['ID'] = list(range(0, 3082))\n",
        "# test_csv['Label'] = np.argmax(test_pred, 1)\n",
        "# test_csv['Label'] = test_csv['Label'].map({1:'pos', 0:'neg'})\n",
        "# test_csv.to_csv('tmp.csv', index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ332skzPDKT"
      },
      "source": [
        "cls_name = np.array(['angry', 'disgusted', 'fearful', 'happy','neutral', 'sad', 'surprised'])\n",
        "submit_df = pd.DataFrame({'name': test_jpg, 'label': cls_name[test_pred.argmax(1)]})\n",
        "submit_df['name'] = submit_df['name'].apply(lambda x: x.split('/')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNVa7vwmPHl3"
      },
      "source": [
        "submit_df = submit_df.sort_values(by='name')\n",
        "submit_df.to_csv('pytorch_submit.csv', index=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}